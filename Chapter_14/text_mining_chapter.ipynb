{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from spellchecker import SpellChecker\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'The class is over. I hopep it is intersting to you. Please let me knoww if not.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the class is over. i hopep it is intersting to you. please let me knoww if not.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change to lower case\n",
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'class', 'is', 'over', '.', 'I', 'hopep', 'it', 'is', 'intersting', 'to', 'you', '.', 'Please', 'let', 'me', 'knoww', 'if', 'not', '.']\n"
     ]
    }
   ],
   "source": [
    "# word tokenization\n",
    "word_tokens = word_tokenize(text)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'hopep', 'intersting', 'please', 'let', 'knoww']\n"
     ]
    }
   ],
   "source": [
    "# remove stop words and punctuations\n",
    "stopword_list = stopwords.words('english')\n",
    "punctuation_list = list(string.punctuation)\n",
    "cleaned_text = [txt for txt in word_tokenize(text.lower()) if txt not in stopword_list+punctuation_list]\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'hope', 'interesting', 'please', 'let', 'know']\n"
     ]
    }
   ],
   "source": [
    "# typo correction\n",
    "spell = SpellChecker()\n",
    "corrected_text = [spell.correction(wd) for wd in cleaned_text]\n",
    "print(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('class', 'NN'),\n",
       " ('hope', 'NN'),\n",
       " ('interesting', 'VBG'),\n",
       " ('please', 'JJ'),\n",
       " ('let', 'NN'),\n",
       " ('know', 'VB')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part of speech tagging\n",
    "pos_tag(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('class', 'class'),\n",
       " ('hope', 'hope'),\n",
       " ('interesting', 'interest'),\n",
       " ('please', 'pleas'),\n",
       " ('let', 'let'),\n",
       " ('know', 'know')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming the words\n",
    "porter = PorterStemmer()\n",
    "stem_words = [porter.stem(txt) for txt in corrected_text]\n",
    "list(zip(corrected_text,stem_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram representation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The class is over.', 'I hopep it is intersting to you.', 'Please let me knoww if not.']\n"
     ]
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "sentence_list = sent_tokenize(text)\n",
    "print(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the stop words removal and typo correction\n",
    "correct_sentence_list = []\n",
    "for sent in sentence_list:\n",
    "    correct_sentence_list.append(' '.join([spell.correction(wd) for wd in word_tokenize(sent.lower()) \\\n",
    "                                  if wd not in stopword_list+punctuation_list]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class', 'hope interesting', 'please let know']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>hope</th>\n",
       "      <th>interesting</th>\n",
       "      <th>know</th>\n",
       "      <th>let</th>\n",
       "      <th>please</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  hope  interesting  know  let  please\n",
       "0      1     0            0     0    0       0\n",
       "1      0     1            1     0    0       0\n",
       "2      0     0            0     1    1       1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unigram\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1)) \n",
    "X = vectorizer.fit_transform(correct_sentence_list)\n",
    "df = pd.DataFrame(X.toarray())\n",
    "df.columns = vectorizer.get_feature_names()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>hope</th>\n",
       "      <th>interesting</th>\n",
       "      <th>know</th>\n",
       "      <th>let</th>\n",
       "      <th>please</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  hope  interesting  know   let  please\n",
       "0    1.0  0.00         0.00  0.00  0.00    0.00\n",
       "1    0.0  0.71         0.71  0.00  0.00    0.00\n",
       "2    0.0  0.00         0.00  0.58  0.58    0.58"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tf-Idf transformation of unigram\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1)) \n",
    "X = vectorizer.fit_transform(correct_sentence_list)\n",
    "df = pd.DataFrame(X.toarray())\n",
    "df.columns = vectorizer.get_feature_names()\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class is</th>\n",
       "      <th>hopep it</th>\n",
       "      <th>if not</th>\n",
       "      <th>intersting to</th>\n",
       "      <th>is intersting</th>\n",
       "      <th>is over</th>\n",
       "      <th>it is</th>\n",
       "      <th>knoww if</th>\n",
       "      <th>let me</th>\n",
       "      <th>me knoww</th>\n",
       "      <th>please let</th>\n",
       "      <th>the class</th>\n",
       "      <th>to you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class is  hopep it  if not  intersting to  is intersting  is over  it is  \\\n",
       "0         1         0       0              0              0        1      0   \n",
       "1         0         1       0              1              1        0      1   \n",
       "2         0         0       1              0              0        0      0   \n",
       "\n",
       "   knoww if  let me  me knoww  please let  the class  to you  \n",
       "0         0       0         0           0          1       0  \n",
       "1         0       0         0           0          0       1  \n",
       "2         1       1         1           1          0       0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bigramI \n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "X = vectorizer.fit_transform(sentence_list)\n",
    "df = pd.DataFrame(X.toarray())\n",
    "df.columns = vectorizer.get_feature_names()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word vectors\n",
    "import gensim.downloader as api\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the 100 dimension word vector dictionary trained on twitter data\n",
    "model = api.load(\"glove-twitter-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38446  , -0.45507  ,  0.45351  ,  0.4301   , -0.050908 ,\n",
       "       -0.26414  ,  0.43253  , -0.3166   ,  0.32214  ,  0.0064333,\n",
       "       -0.47066  ,  0.95335  , -3.2063   ,  0.010913 , -0.27565  ,\n",
       "        1.1732   ,  0.52033  , -0.045973 ,  0.094254 , -0.53846  ,\n",
       "        0.0035668,  0.11934  , -0.17815  , -0.58093  ,  0.65081  ,\n",
       "       -0.48746  , -0.50961  ,  0.42771  , -0.30638  ,  0.32385  ,\n",
       "        0.33687  , -0.1717   , -0.39104  , -0.19038  ,  0.37016  ,\n",
       "       -0.50396  ,  0.041969 , -0.20517  ,  0.3223   ,  0.41217  ,\n",
       "       -0.42191  , -0.26359  , -0.1773   , -0.35658  ,  0.52145  ,\n",
       "        0.57282  ,  0.60204  ,  0.74369  ,  0.33377  , -0.45041  ,\n",
       "        0.015978 , -0.12575  ,  0.29786  , -0.77635  ,  0.23759  ,\n",
       "        0.63821  ,  0.63726  ,  1.0079   ,  0.13714  , -0.031928 ,\n",
       "       -0.21299  ,  0.52348  ,  0.67934  , -0.1427   , -0.64236  ,\n",
       "       -0.47996  , -0.87915  ,  0.17501  ,  0.64517  ,  0.3778   ,\n",
       "        0.53493  , -0.29723  , -0.25206  , -0.757    ,  0.33647  ,\n",
       "        0.053759 , -0.8084   ,  0.22205  ,  0.10799  , -0.68982  ,\n",
       "        1.5073   ,  0.96641  , -0.51839  ,  0.32803  ,  0.11878  ,\n",
       "       -0.72009  ,  0.23227  ,  0.098733 , -0.096396 ,  0.40295  ,\n",
       "       -0.003925 , -0.10405  , -0.15234  ,  0.17573  ,  0.29694  ,\n",
       "        0.14938  ,  0.11754  ,  0.15699  , -0.34272  ,  0.2435   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the vector of the word cat\n",
    "model.get_vector('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dog', 0.8752089142799377),\n",
       " ('kitty', 0.8015091419219971),\n",
       " ('pet', 0.7986467480659485),\n",
       " ('cats', 0.797942578792572),\n",
       " ('kitten', 0.7936834096908569),\n",
       " ('puppy', 0.7702749967575073),\n",
       " ('monkey', 0.758426308631897),\n",
       " ('bear', 0.7507944107055664),\n",
       " ('dogs', 0.7460063099861145),\n",
       " ('pig', 0.7117345333099365)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the most similar words as cat\n",
    "model.most_similar('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6474888920783997"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine similarity between cat and tiger\n",
    "1-cosine(model.get_vector('cat'), model.get_vector('tiger'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7936834692955017"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cosine similarity between cat and kitten\n",
    "1-cosine(model.get_vector('cat'), model.get_vector('kitten'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5291033983230591"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cosine similarit between cat and car\n",
    "1-cosine(model.get_vector('cat'), model.get_vector('car'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
